# app.py
import sys, platform, pickle, json, os
import numpy as np
import pandas as pd
import streamlit as st

# ---- import pgmpy VE only (no BayesianModel needed) ----
try:
    from pgmpy.inference import VariableElimination
except ModuleNotFoundError:
    st.error("pgmpy is not installed.")
    st.code(
        "pip install --upgrade pip setuptools wheel\n"
        "pip install pgmpy numpy pandas networkx scipy streamlit",
        language="bash",
    )
    st.stop()

PICKLE_PATH = "bn_pgmpy.pkl"

# ---------- Page + styles ----------
st.set_page_config(page_title="Purchase Intention Predictor", page_icon="üõçÔ∏è", layout="centered")
st.markdown(
    """
    <style>
      :root { --accent:#2563eb; }
      .block-container {max-width: 980px;}
      h1, .stMarkdown h1 { letter-spacing: -0.3px; }
      h2, .stMarkdown h2 { margin-top: 0.25rem; }
      .section { background:#fbfcfe; border:1px solid #eef0f4; border-radius:14px; padding:18px 18px 12px; margin: 14px 0 10px; }
      .section h2 { margin: 0 0 14px 0; }
      .metric-card {background:#f8f9fb; padding:12px 16px; border-radius:14px; border:1px solid #eef0f4;}
      .stRadio > label {font-weight:600;}
      .st-emotion-cache-16idsys p { margin-bottom: 0.35rem; } /* tighten labels */
      input[type="radio"]:checked { accent-color: var(--accent); }
    </style>
    """,
    unsafe_allow_html=True
)

st.title("üõçÔ∏è Purchase Intention (Bayesian Network)")


# ---------- load the bundle ----------
@st.cache_resource(show_spinner=False)
def load_bundle(path: str):
    with open(path, "rb") as f:
        return pickle.load(f)

try:
    bundle = load_bundle(PICKLE_PATH)
except Exception as e:
    st.error(f"‚ùå Failed to load pickle at '{PICKLE_PATH}': {e}")
    st.stop()

# basic key checks
for k in ("model", "target", "classes", "state_names"):
    if k not in bundle:
        st.error(f"‚ùå Pickle missing required key: {k}")
        st.stop()

model = bundle["model"]
target_node = bundle["target"]
classes = bundle["classes"]
state_names = bundle["state_names"]  # typically: dict node -> list of states

# ---------- NO-RETRAIN, NO-REBUILD: lightweight pgmpy shims ----------
# 1) Some VE versions call model.check_model()
if not hasattr(model, "check_model"):
    def _noop_check_model(*args, **kwargs):
        return True
    try:
        model.check_model = _noop_check_model
    except Exception:
        pass

# 2) Some VE versions expect model.factors; derive from CPDs if missing
if not hasattr(model, "factors"):
    try:
        cpds = model.get_cpds()
    except Exception:
        cpds = []
    factors = []
    for cpd in cpds:
        tf = getattr(cpd, "to_factor", None)
        if callable(tf):
            try:
                factors.append(tf()); continue
            except Exception:
                pass
        factors.append(cpd)
    try:
        model.factors = factors
    except Exception:
        pass

# ---------- helpers ----------
def pick_existing_node(state_names_dict, candidates: list[str]):
    if isinstance(state_names_dict, dict):
        for c in candidates:
            if c in state_names_dict:
                return c
    return None

def clamp_round_1_to_5(x: float) -> int:
    return int(min(5, max(1, round(x))))

def median_from_lookup(medians_dict, demo_name, demo_label_value, fallback=3):
    d = medians_dict.get(demo_name, {})
    if demo_label_value == "Only when needed" and "Only when\nneeded" in d:
        demo_label_value = "Only when\nneeded"
    return int(d.get(demo_label_value, fallback))

def averaged_score_for_var(var_medians_dict, demo_answers_labels: dict) -> int:
    vals = []
    for demo_name, demo_label in demo_answers_labels.items():
        if demo_label:
            vals.append(median_from_lookup(var_medians_dict, demo_name, demo_label, fallback=3))
    if not vals:
        return 3
    return clamp_round_1_to_5(float(np.mean(vals)))

def predict_purchase(bundle_obj, evidence: dict):
    ve = VariableElimination(bundle_obj["model"])
    q = ve.query([bundle_obj["target"]], evidence=evidence, show_progress=False)
    probs = dict(zip(q.state_names[bundle_obj["target"]], q.values.flatten().astype(float)))
    prob_vec = np.array([probs.get(c, 0.0) for c in bundle_obj["classes"]], dtype=float)
    idx = int(prob_vec.argmax())
    return bundle_obj["target"], bundle_obj["classes"][idx], float(prob_vec[idx]), bundle_obj["classes"], prob_vec

# ---------- label mapping (pretty UI ‚Üî string codes the model expects) ----------
LABEL_MAP_PATH = "state_label_map.json"  # optional override
DEFAULT_LABELS = {
    "Gender": {"1": "Male", "2": "Female", "3": "Prefer not to say"},
    "Age": {"1": "18‚Äì22", "2": "23‚Äì28", "3": "29‚Äì35", "4": "35‚Äì49", "5": "50‚Äì65"},
    "Marital_Status": {"1": "Married", "2": "Single", "3": "Prefer not to say"},
    "Employment_Status": {"1": "Employed", "2": "Unemployed", 1: "Employed", 2: "Unemployed"},
    # Updated per your training mapping (include string and int keys, just in case)
    "Level_of_Education": {
        "1": "No formal", "2": "Basic", "3": "Diploma", "4": "Degree", "5": "Postgrad",
        1: "No formal", 2: "Basic", 3: "Diploma", 4: "Degree", 5: "Postgrad",
    },
    "Shopping_frequency": {"1": "1‚Äì2x/week", "2": "2‚Äì3x/week", "3": "3‚Äì4x/week", "4": "5‚Äì6x/week", "5": "6‚Äì7x/week"},
    "Regular_Customer": {"1": "Regular", "2": "Only when needed"},
    # Likert nodes already "1".."5"; formatted separately.
}

def load_label_map(state_names_dict) -> dict:
    labels = {}
    if isinstance(state_names_dict, dict):
        for node, states in state_names_dict.items():
            base = DEFAULT_LABELS.get(node, {})
            labels[node] = {s: base.get(s, s) for s in states}  # identity fallback
    if os.path.exists(LABEL_MAP_PATH):
        try:
            with open(LABEL_MAP_PATH, "r", encoding="utf-8") as f:
                override = json.load(f)
            for node, mapping in override.items():
                if node in labels:
                    labels[node].update(mapping)
        except Exception as e:
            st.warning(f"Could not read {LABEL_MAP_PATH}: {e}")
    return labels

LABELS = load_label_map(state_names)

def radio_mapped(title: str, node_key: str, *, horizontal: bool = True):
    """Show pretty labels only; return the underlying BN state code (string)."""
    opts = state_names.get(node_key, []) if isinstance(state_names, dict) else []
    if not opts:
        return None
    pretty = [LABELS.get(node_key, {}).get(code, code) for code in opts]
    idx = st.radio(title, list(range(len(opts))), format_func=lambda i: pretty[i], horizontal=horizontal)
    return opts[idx]  # underlying string code

def likert_radio(title: str, node_key: str):
    opts = state_names.get(node_key, ["1", "2", "3", "4", "5"]) if isinstance(state_names, dict) else ["1","2","3","4","5"]
    pretty = {
        "1": "1 = Strongly disagree",
        "2": "2 = Disagree",
        "3": "3 = Indifferent",
        "4": "4 = Agree",
        "5": "5 = Strongly agree",
    }
    idx = st.radio(title, list(range(len(opts))), format_func=lambda i: pretty.get(opts[i], opts[i]), horizontal=True)
    return opts[idx]

# ---------- discover node names (underscore / space tolerant) ----------
Gender = pick_existing_node(state_names, ["Gender"])
Age = pick_existing_node(state_names, ["Age"])
Marital_Status = pick_existing_node(state_names, ["Marital_Status", "Marital Status"])
Employment_Status = pick_existing_node(state_names, ["Employment_Status", "Employment Status"])
Level_of_Education = pick_existing_node(state_names, ["Level_of_Education", "Level of Education"])
Regular_Customer = pick_existing_node(state_names, ["Regular_Customer", "Regular Customer", "Customer_Type", "Customer Type"])
Shopping_frequency = pick_existing_node(state_names, ["Shopping_frequency", "Shopping frequency"])

Empathy = pick_existing_node(state_names, ["Empathy"])
Convenience = pick_existing_node(state_names, ["Convenience"])
Customer_Trust = pick_existing_node(state_names, ["Customer_Trust", "Customer Trust"])

Perceived_Value = pick_existing_node(state_names, ["Perceived_Value", "Perceived Value"])
Perceived_Product_Quality = pick_existing_node(state_names, ["Perceived_Product_Quality", "Perceived Product Quality"])
Physical_Environment = pick_existing_node(state_names, ["Physical_Environment", "Physical Environment"])
Price_Sensitivity = pick_existing_node(state_names, ["Price_Sensitivity", "Price Sensitivity"])

# ---------- medians (use FRIENDLY LABELS, not codes) ----------
# You can tune these if you have empirical medians by segment.
empathy_medians = {
    "Gender": {"Male": 4, "Female": 4, "Prefer not to say": 3},
    "Age": {"18‚Äì22": 3, "23‚Äì28": 4, "29‚Äì35": 4, "35‚Äì49": 3, "50‚Äì65": 4},
    "Marital_Status": {"Married": 4, "Single": 4, "Prefer not to say": 3},
    "Shopping_frequency": {"1‚Äì2x/week": 3, "2‚Äì3x/week": 4, "3‚Äì4x/week": 4, "5‚Äì6x/week": 4, "6‚Äì7x/week": 4},
    "Regular_Customer": {"Regular": 4, "Only when\nneeded": 3, "Only when needed": 3},
    "Employment_Status": {"Employed": 4, "Unemployed": 4},
    # If you want Level_of_Education to influence these, add values like below:
    # "Level_of_Education": {"No formal": 3, "Basic": 3, "Diploma": 4, "Degree": 4, "Postgrad": 4},
}
convenience_medians = {
    "Gender": {"Male": 4, "Female": 4, "Prefer not to say": 3},
    "Age": {"18‚Äì22": 3, "23‚Äì28": 4, "29‚Äì35": 4, "35‚Äì49": 4, "50‚Äì65": 4},
    "Marital_Status": {"Married": 4, "Single": 4, "Prefer not to say": 5},
    "Shopping_frequency": {"1‚Äì2x/week": 4, "2‚Äì3x/week": 4, "3‚Äì4x/week": 5, "5‚Äì6x/week": 5, "6‚Äì7x/week": 2},
    "Regular_Customer": {"Regular": 4, "Only when\nneeded": 3, "Only when needed": 3},
    "Employment_Status": {"Employed": 4, "Unemployed": 4},
    # "Level_of_Education": {"No formal": 3, "Basic": 3, "Diploma": 4, "Degree": 4, "Postgrad": 4},
}
customer_trust_medians = {
    "Gender": {"Male": 4, "Female": 3, "Prefer not to say": 3},
    "Age": {"18‚Äì22": 4, "23‚Äì28": 4, "29‚Äì35": 3, "35‚Äì49": 4, "50‚Äì65": 3},
    "Marital_Status": {"Married": 4, "Single": 3, "Prefer not to say": 3},
    "Shopping_frequency": {"1‚Äì2x/week": 3, "2‚Äì3x/week": 4, "3‚Äì4x/week": 3, "5‚Äì6x/week": 5, "6‚Äì7x/week": 3},
    "Regular_Customer": {"Regular": 4, "Only when\nneeded": 3, "Only when needed": 3},
    "Employment_Status": {"Employed": 3, "Unemployed": 4},
    # "Level_of_Education": {"No formal": 3, "Basic": 3, "Diploma": 4, "Degree": 4, "Postgrad": 4},
}

# =========================================================
# 1) DEMOGRAPHICS
# =========================================================
st.markdown('<div class="section">', unsafe_allow_html=True)
st.header("1) Demographics")
col1, col2 = st.columns(2, gap="large")
with col1:
    ui_gender_code = radio_mapped("Gender", Gender, horizontal=True)
    ui_age_code = radio_mapped("Age", Age, horizontal=True)
    ui_marital_code = radio_mapped("Marital Status", Marital_Status, horizontal=True)
    ui_regular_code = radio_mapped("Customer Type", Regular_Customer, horizontal=True)
with col2:
    ui_empstat_code = radio_mapped("Employment Status", Employment_Status, horizontal=True)
    ui_edu_code = radio_mapped("Level of Education", Level_of_Education, horizontal=True)
    ui_shopfreq_code = radio_mapped("Shopping frequency", Shopping_frequency, horizontal=False)
    
st.markdown('</div>', unsafe_allow_html=True)

# convert codes -> labels for median lookup
def label_of(node_key, code):
    return LABELS.get(node_key, {}).get(code, code)

demo_labels = {
    "Gender": label_of(Gender, ui_gender_code) if ui_gender_code else None,
    "Age": label_of(Age, ui_age_code) if ui_age_code else None,
    "Marital_Status": label_of(Marital_Status, ui_marital_code) if ui_marital_code else None,
    "Employment_Status": label_of(Employment_Status, ui_empstat_code) if ui_empstat_code else None,
    "Level_of_Education": label_of(Level_of_Education, ui_edu_code) if ui_edu_code else None,
    "Shopping_frequency": label_of(Shopping_frequency, ui_shopfreq_code) if ui_shopfreq_code else None,
    "Regular_Customer": label_of(Regular_Customer, ui_regular_code) if ui_regular_code else None,
}

# =========================================================
# 2) AUTO-COMPUTED
# =========================================================
st.markdown('<div class="section">', unsafe_allow_html=True)
st.header("2) Auto-computed (from demographics)")
emp_score = averaged_score_for_var(empathy_medians, demo_labels)
conv_score = averaged_score_for_var(convenience_medians, demo_labels)
trust_score = averaged_score_for_var(customer_trust_medians, demo_labels)

c1, c2, c3 = st.columns(3)
for col, title, val in zip((c1, c2, c3),
                           ("Empathy (1‚Äì5)", "Convenience (1‚Äì5)", "Customer Trust (1‚Äì5)"),
                           (emp_score, conv_score, trust_score)):
    with col:
        st.markdown('<div class="metric-card">', unsafe_allow_html=True)
        st.metric(title, val)
        st.markdown("</div>", unsafe_allow_html=True)
st.markdown('</div>', unsafe_allow_html=True)

# =========================================================
# 3) CUSTOMER ANSWERS
# =========================================================
st.markdown('<div class="section">', unsafe_allow_html=True)
st.header("3) Customer answers (1‚Äì5)")
q_val_code = likert_radio("Perceived Value", Perceived_Value)
q_qual_code = likert_radio("Perceived Product Quality", Perceived_Product_Quality)
q_env_code = likert_radio("Physical Environment", Physical_Environment)
q_price_code = likert_radio("Price Sensitivity", Price_Sensitivity)
st.markdown('</div>', unsafe_allow_html=True)

# build evidence (send STRING CODES ONLY)
evidence = {}
def put(node_key, code_str):
    if node_key and code_str is not None:
        evidence[node_key] = str(code_str)

put(Gender, ui_gender_code)
put(Age, ui_age_code)
put(Marital_Status, ui_marital_code)
put(Employment_Status, ui_empstat_code)
put(Level_of_Education, ui_edu_code)
put(Shopping_frequency, ui_shopfreq_code)
put(Regular_Customer, ui_regular_code)

put(Empathy, str(emp_score))
put(Convenience, str(conv_score))
put(Customer_Trust, str(trust_score))

put(Perceived_Value, q_val_code)
put(Perceived_Product_Quality, q_qual_code)
put(Physical_Environment, q_env_code)
put(Price_Sensitivity, q_price_code)

# =========================================================
# 4) PREDICTION
# =========================================================
st.markdown('<div class="section">', unsafe_allow_html=True)
st.header("4) Prediction")

if st.button("Predict Purchase Intention", type="primary"):
    try:
        tgt, pred_class, conf, cls, prob_vec = predict_purchase(bundle, evidence)

        # Pretty labels for classes (customize if you want)
        def pretty_class(c: str) -> str:
            mapping = {"1": "Very Low", "2": "Low", "3": "Medium", "4": "High", "5": "Very High"}
            return mapping.get(str(c), str(c))

        st.success(f"Predicted **{tgt}**: **{pretty_class(pred_class)}**  |  Confidence: **{conf*100:.1f}%**")
        st.progress(int(round(conf*100)))

        prob_df = pd.DataFrame({"Class": [pretty_class(c) for c in cls], "Probability": prob_vec}).sort_values("Probability", ascending=False)
        st.dataframe(prob_df.style.format({"Probability": "{:.3f}"}), use_container_width=True, hide_index=True)


    except Exception as e:
        st.error(f"Prediction failed: {e}")
        with st.expander("Evidence (debug)"):
            st.json(evidence)

st.markdown('</div>', unsafe_allow_html=True)
